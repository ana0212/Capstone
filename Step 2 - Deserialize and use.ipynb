{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "[1. Deserialize the model stuff](#1.-Deserialize-the-model-stuff)   \n",
    "[2. Deserialize and prepare the observation](#2.-Deserialize-and-prepare-the-observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Deserialize the model stuff\n",
    "\n",
    "Now here's a pretty cool thing: we are going to predict on a new\n",
    "observation with only the imports we have above. Notice that there's\n",
    "nothing about scikit up there.\n",
    "\n",
    "If you can remember from the previous notebook, there were 3\n",
    "things that we serialized, so now we need to deserialize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's deserialize the columns from the super handy json format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('columns.json', 'r') as fh:\n",
    "    columns = json.load(fh)\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's un-pickle the dtypes as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dtypes.pickle', 'rb') as fh:\n",
    "    dtypes = pickle.load(fh)\n",
    "dtypes    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's load the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = joblib.load('pipeline.pickle')\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we've got everything that we need in order to make\n",
    "a new prediction! All that's needed is the prediction itself,\n",
    "which should come in a json format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deserialize and prepare the observation\n",
    "\n",
    "This is exactly as we saw in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_obs_str = '{\"Age\": 22.0, \"Cabin\": null, \"Embarked\": \"S\", \"Fare\": 7.25, \"Parch\": 0, \"Pclass\": 3, \"Sex\": \"male\", \"SibSp\": 1}'\n",
    "new_obs_dict = json.loads(new_obs_str)\n",
    "obs = pd.DataFrame([new_obs_dict], columns=columns)\n",
    "obs = obs.astype(dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which leaves us with a dataframe containing a single observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which in turn can be passed into predict_proba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = pipeline.predict_proba(obs)\n",
    "outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a binary classification task, the outcome array has two entries for each observation: the 0th entry corresponds to the probability of being in the *negative class (or 0 in our case*), while the 1st corresponds to the probability of being in the *positive class (or 1 in our case)*.\n",
    "\n",
    "So, if we want to know the likelihood of surviving, we need to look at the probability of being in the positive class, which you can access like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there's only a single observation... so yeah\n",
    "observation_index = 0\n",
    "# This is the trick, go for the the positive class index\n",
    "positive_class_index = 1\n",
    "# Indexing in numpy arrays is a bit different than in normal\n",
    "# python arrays:\n",
    "survival_probability = outcome[observation_index, positive_class_index]\n",
    "print('The observation has {} probability of survival.'.format(survival_probability))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
